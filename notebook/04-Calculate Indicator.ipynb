{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing Mobile Positioning Data (MPD) to Measure SDGs Indicator 17.8.1: Proportion of Individuals Using the Internet\n",
    "\n",
    "## Summary\n",
    "\n",
    "`SDG Indicator 17.8.1` aims to assess the proportion of individuals using the Internet, specifically those who have accessed it within the last three months. The Internet, being a global computer network that facilitates various communication services like the World Wide Web, email, news, and entertainment, can be accessed through different devices such as computers, mobile phones, tablets, PDAs, gaming consoles, and digital TVs. Connectivity may be established through fixed or mobile networks.\n",
    "\n",
    "Leveraging mobile phone data offers a valuable avenue for estimating and enhancing the measurement of this indicator. The utilization of mobile phone data can significantly contribute to the accurate and detailed assessment of SDG Indicator 17.8.1 by providing real-time and granular information on Internet usage. However, it is essential to approach data privacy, data quality, and the need for complementary data sources with careful consideration to ensure the reliability and effectiveness of the measurement process.\n",
    "\n",
    "When feasible, the indicator can be further analyzed by various breakdowns and disaggregation criteria, such as regional distinctions (urban and rural areas), gender, age groups, etc. The International Telecommunication Union (ITU) collects data from countries encompassing these breakdowns to enhance the comprehensiveness of the indicator's assessment.\n",
    "\n",
    "## Calculation of Indicator\n",
    "\n",
    "### add highlight for hashing consistency from MNO\n",
    "\n",
    "To obtain geographical coordinates and facilitate data aggregation, it is essential to combine Mobile Positioning Data (MPD) with cell data obtained from Mobile Network Operators (MNOs) or other publicly available sources. The cell data includes approximate geographical coordinates and the corresponding technology used. Each cell's location, categorized as the subscriber's home location, is then aggregated at the desired geographical level, such as LAU 2, and separated based on the technology used for internet connectivity.\n",
    "\n",
    "The following assumptions are made regarding subscriber internet usage:\n",
    "\n",
    "- If a subscriber has no mobile internet traffic (IPDR), it is assumed that they do not have internet access.\n",
    "- If a subscriber only has mobile internet traffic in 2G cells (without any events in 3G or 4G), it is presumed that they solely use the internet through 2G.\n",
    "- If a subscriber has any mobile internet traffic in 3G cells (potentially in 2G as well, but not in 4G), it is inferred that they use the internet through 3G.\n",
    "- If a subscriber has any mobile internet traffic in 4G cells (and may also have usage in 2G and 3G), it is deduced that they utilize 4G for internet connectivity.\n",
    "\n",
    "The resulting dataset contains the following fields:\n",
    "\n",
    "- Level of aggregation, which can be demographic variables like gender and age group, administrative area, or a combination of them.\n",
    "- total_home_count: number of persons with detected homes.\n",
    "- no_data_home_count: number of subscribers who have no mobile internet traffic and have detected homes.\n",
    "- 2G_home_count (2G): number of subscribers who have 2G mobile data traffic and a detected home.\n",
    "- 3G_home_count (3G): number of subscribers who have 3G mobile data traffic and a detected home.\n",
    "- 4G_home_count (4G): number of subscribers who have 4G data traffic and a detected home.\n",
    "\n",
    "The resulting table will show the proportion of subscribers using the internet by technology in each group. To extrapolate this information to the rest of the population, additional data on mobile access is required. Since the MNO was also asked to indicate the cell type (2G, 3G, or 4G), the geographical distribution should be checked by cell type through visual analysis.\n",
    "\n",
    "## Steps for Measurement\n",
    "1. **Define the Scope of Aggregation**: Determine the geographic level (global, regional, national, or local) and specify the partnerships or initiatives to be considered for measurement.\n",
    "2. **Identify Data Sources**: Join information from anchoring process with another data source like Customer relationship management (CRM) data that containing information about subscribers demography, and other data relevant data sources.\n",
    "3. **Calculate the Indicator**: Use the formula below to calculate the indicator:\n",
    "   ```\n",
    "   Indicator 17.8.1 = (Number of individuals using the internet / Total number of individuals in the target population) x 100%\n",
    "   ```\n",
    "4. **Data Validation**: Validate the accuracy and reliability of the proxy indicator from mobile data by comparing it with other source including conventional survey to ensure its quality and coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sys module to adjust the Python system path\n",
    "import sys\n",
    "\n",
    "# Append a path to the system path so that Python can import modules from the specified directory (relative path)\n",
    "sys.path.append('../')\n",
    "\n",
    "# Import the CONF, QA_summary and QA_action_plan variables from the script.QA module\n",
    "from script.conf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module to interact with the operating system\n",
    "import os\n",
    "\n",
    "# Try to create a new directory at the path QA_PATH using os.mkdir()\n",
    "# If the directory already exists, print a message stating that it does\n",
    "try:\n",
    "    os.mkdir(INDICATOR_PATH)\n",
    "    print(\"Create new folder {}\".format(INDICATOR_PATH))\n",
    "except FileExistsError:\n",
    "    print(\"Folder {} already exists\".format(INDICATOR_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module to interact with the operating system\n",
    "import os\n",
    "\n",
    "# Import Pandas module\n",
    "import pandas as pd\n",
    "\n",
    "# Import the PySpark module\n",
    "import pyspark\n",
    "\n",
    "# Import the Seaborn module\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "sns.set_color_codes(\"pastel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import year, month, dayofmonth, substring, col, floor, expr, when, mean, count\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Import the SparkSession from PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession with the specified configuration\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[{}]\".format(CORE))\\\n",
    "        .appName(\"02.ITU.PySpark-Indicator\")\\\n",
    "        .config('spark.sql.execution.arrow.pyspark.enabled', 'true')\\\n",
    "        .config('spark.eventLog.gcMetrics.youngGenerationGarbageCollectors', 'true')\\\n",
    "        .config('spark.ui.port', '4050')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Print the spark object which contains the SparkSession\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code below to connect your remote spark cluster instead.\n",
    "\n",
    "# # Import the PySpark module\n",
    "# import pyspark\n",
    "# from pyspark.sql.types import StructType, StructField, StringType, FloatType, TimestampType\n",
    "\n",
    "# import pyspark.sql.functions as f\n",
    "# from pyspark.sql.functions import year, month, dayofmonth, substring, col, to_date\n",
    "# from pyspark.sql.window import Window\n",
    "\n",
    "# # Import the SparkSession from PySpark\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# CLUSTER_URL = \"spark://master\"\n",
    "# PORT = \"7077\"\n",
    "\n",
    "# # Create a SparkSession with the specified configuration remote server\n",
    "# spark = SparkSession.builder\\\n",
    "#         .master(\"{}:{}\".format(CLUSTER_URL,PORT))\\\n",
    "#         .appName(\"01.ITU.PySpark-Raw\")\\\n",
    "#         .getOrCreate()\n",
    "\n",
    "# # Print the spark object which contains the SparkSession\n",
    "# spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the cell administrative location file. In this example, we will use data generated from QA step\n",
    "# This is mandatory file that will be needed for indicator aggregation\n",
    "path_cell = QA_PATH+'5_cell_administrative_location.csv'\n",
    "\n",
    "# Read the cell administrative location file using Spark\n",
    "cell = spark.read.format('csv')\\\n",
    "    .options(delimiter='\\t',inferSchema=\"true\")\\\n",
    "    .option('header',True)\\\n",
    "    .load(path_cell)\n",
    "\n",
    "# Rename the 'cell_id' column to 'anchor_cell_id'\n",
    "cell = cell.withColumnRenamed('cell_id','anchor_cell_id')\n",
    "cell.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the zone file\n",
    "path_zone = BASE_PATH+INDICATOR_ZONE_PATH\n",
    "\n",
    "if os.path.exists(path=path_zone):\n",
    "    ZONE_FLAG = True\n",
    "    # Read the zone file using Spark\n",
    "    zone = spark.read.format('csv')\\\n",
    "        .options(delimiter='\\t',inferSchema=\"true\")\\\n",
    "        .option('header',True)\\\n",
    "        .load(path_zone)\n",
    "\n",
    "    # Rename the 'cell_id' column to 'anchor_cell_id'\n",
    "    zone = zone.withColumnRenamed('cell_id','anchor_cell_id')\n",
    "    zone.show(5)\n",
    "else:\n",
    "    ZONE_FLAG = False\n",
    "    print(\"Information about ZONAL CLASSIFICATION (Urban, Rural) of the cell location is missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the CRM file\n",
    "path_crm = BASE_PATH+INDICATOR_CRM_PATH\n",
    "\n",
    "if os.path.exists(path=path_crm):\n",
    "    CRM_FLAG = True\n",
    "    # Read the CRM file using Spark\n",
    "    crm = spark.read.format('csv')\\\n",
    "        .options(delimiter='\\t',inferSchema=\"true\")\\\n",
    "        .option('header',True)\\\n",
    "        .load(path_crm)\n",
    "\n",
    "    # Create a new column 'age_group' by concatenating the age range\n",
    "    crm = crm.withColumn('age_group',expr(\"concat(floor(age / 10) * 10, '-', floor(age / 10) * 10 + 10)\"))\n",
    "\n",
    "    # Show the contents of the CRM DataFrame\n",
    "    crm.show()\n",
    "else:\n",
    "    CRM_FLAG = False\n",
    "    print(\"Information about CUSTOMER RELATIONSHIP MANAGEMENT (Gender, Age Group) of the subscribers is missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the user anchor final file\n",
    "path = ANCHOR_PATH+'user_anchor_final.csv'\n",
    "\n",
    "# Read the user anchor final file using Spark, specifying the file format as CSV and setting the delimiter as tab. It also infers the schema from the data and treats the first row as the header.\n",
    "df = spark.read.format('csv')\\\n",
    "    .options(delimiter='\\t',inferSchema=\"true\")\\\n",
    "    .option('header',True)\\\n",
    "    .load(path)\n",
    "\n",
    "# Filter out rows where the 'anchor_cell_id' column is null\n",
    "df = df.filter(col('anchor_cell_id').isNotNull())\n",
    "\n",
    "# Join the df DataFrame with the cell DataFrame on the 'anchor_cell_id' column, using a left join\n",
    "df = df.join(cell,['anchor_cell_id'],how='left')\n",
    "\n",
    "if ZONE_FLAG:\n",
    "    # Join the df DataFrame with the zone DataFrame on the 'anchor_cell_id' column, using a left join\n",
    "    df = df.join(zone,['anchor_cell_id'],how='left')\n",
    "\n",
    "\n",
    "if CRM_FLAG:\n",
    "    # Join the df DataFrame with the crm DataFrame on the 'msisdn' column, using a left join\n",
    "    df = df.join(crm,['msisdn'],how='left')\n",
    "\n",
    "df.cache()\n",
    "\n",
    "# Show the contents of the df DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code starts by defining a variable `tech_col` with the value 'IPDR_highest_service'.\n",
    "\n",
    "Then, it uses the `groupBy()` function on a DataFrame `df` to group the data by the 'municipality' column.\n",
    "\n",
    "After that, it calls the `agg()` function to perform multiple aggregation operations on the grouped data. Each aggregation operation is specified as a separate argument to the `agg()` function.\n",
    "\n",
    "Here are the aggregation operations being performed:\n",
    "\n",
    "1. `count(col('msisdn')).alias('total_home_count')`: This counts the number of rows in each group and assigns the alias 'total_home_count' to the resulting column.\n",
    "\n",
    "2. `count(when(col('internet_user')==False,col('msisdn'))).alias('total_no_internet')`: This counts the number of rows where the 'internet_user' column is False, and assigns the alias 'total_no_internet' to the resulting column.\n",
    "\n",
    "3. `count(when((col('internet_user')==True) & (col(tech_col)=='2G'),col('msisdn'))).alias('total_internet_2G')`: This counts the number of rows where the 'internet_user' column is True and the 'IPDR_highest_service' column is '2G', and assigns the alias 'total_internet_2G' to the resulting column.\n",
    "\n",
    "4. `count(when((col('internet_user')==True) & (col(tech_col)=='3G'),col('msisdn'))).alias('total_internet_3G')`: This counts the number of rows where the 'internet_user' column is True and the 'IPDR_highest_service' column is '3G', and assigns the alias 'total_internet_3G' to the resulting column.\n",
    "\n",
    "5. `count(when((col('internet_user')==True) & (col(tech_col)=='4G'),col('msisdn'))).alias('total_internet_4G')`: This counts the number of rows where the 'internet_user' column is True and the 'IPDR_highest_service' column is '4G', and assigns the alias 'total_internet_4G' to the resulting column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column name to be used in the aggregation\n",
    "tech_col = 'IPDR_highest_service'\n",
    "\n",
    "# Group the dataframe 'df' by the 'municipality' column and perform aggregations\n",
    "ind_adm = df.groupBy(['municipality']).agg(\n",
    "        count(col('msisdn')).alias('total_home_count'),  # Count the number of 'msisdn' values and alias the column as 'total_home_count'\n",
    "        count(when(col('internet_user')==False, col('msisdn'))).alias('total_no_internet'),  # Count the number of 'msisdn' values where 'internet_user' is False and alias the column as 'total_no_internet'\n",
    "        count(when(col('internet_user')==True, col('msisdn'))).alias('total_internet_ALL'),  # Count the number of 'msisdn' values where 'internet_user' is True, and alias the column as 'total_internet_ALL'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='2G'), col('msisdn'))).alias('total_internet_2G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '2G', and alias the column as 'total_internet_2G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='3G'), col('msisdn'))).alias('total_internet_3G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '3G', and alias the column as 'total_internet_3G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='4G'), col('msisdn'))).alias('total_internet_4G')  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '4G', and alias the column as 'total_internet_4G'\n",
    "    )\\\n",
    "    .orderBy(['total_internet_ALL'],ascending=False).toPandas()\n",
    "\n",
    "ind_adm['perc_no_internet'] = (ind_adm['total_no_internet'] / ind_adm['total_home_count'].replace({0: pd.NA}))\n",
    "ind_adm['perc_internet'] = (ind_adm['total_internet_ALL'] / ind_adm['total_home_count'].replace({0: pd.NA}))\n",
    "ind_adm['perc_internet_2G'] = (ind_adm['total_internet_2G'] / ind_adm['total_home_count'].replace({0: pd.NA}))\n",
    "ind_adm['perc_internet_3G'] = (ind_adm['total_internet_3G'] / ind_adm['total_home_count'].replace({0: pd.NA}))\n",
    "ind_adm['perc_internet_4G'] = (ind_adm['total_internet_4G'] / ind_adm['total_home_count'].replace({0: pd.NA}))\n",
    "\n",
    "ind_adm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_adm.to_csv(INDICATOR_PATH+\"ind_adm.csv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 14))  # wider=10, taller=14 (increase this height to make it taller)\n",
    "ax = sns.barplot(\n",
    "    data=ind_adm,\n",
    "    y='municipality',\n",
    "    x='perc_internet',\n",
    "    hue='municipality',\n",
    "    orient='h'\n",
    ")\n",
    "\n",
    "# Make axis labels and tick labels smaller\n",
    "ax.set_xlabel('perc_internet', fontsize=10)\n",
    "ax.set_ylabel('municipality', fontsize=10)\n",
    "ax.tick_params(axis='both', labelsize=8)\n",
    "\n",
    "# Optional: shrink legend text too\n",
    "leg = ax.get_legend()\n",
    "if leg is not None:\n",
    "    leg.set_title(None)\n",
    "    for t in leg.texts:\n",
    "        t.set_fontsize(8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing geopandas and shapely.geometry libraries \n",
    "import json, geopandas as gpd\n",
    "from shapely.geometry import Point, shape\n",
    "import folium\n",
    "\n",
    "# Providing the path to the GeoJSON file containing administrative boundaries. \n",
    "\n",
    "# Option 1 of reading GEOJSON_FILE - requires Fiona package\n",
    "#adm_boundaries = gpd.read_file(GEOJSON_FILE)\n",
    "\n",
    "# Option 2 of reading GEOJSON_FILE\n",
    "with open(GEOJSON_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    gj = json.load(f)\n",
    "\n",
    "features = gj[\"features\"]\n",
    "geoms = [shape(feat[\"geometry\"]) for feat in features]\n",
    "props = [feat.get(\"properties\", {}) for feat in features]\n",
    "\n",
    "adm_boundaries = gpd.GeoDataFrame(props, geometry=geoms, crs=\"EPSG:4326\")\n",
    "adm_boundaries = adm_boundaries.rename(columns={MUNICIPALITY_FIELD_NAME:'municipality'})\n",
    "\n",
    "adm_boundaries = adm_boundaries.merge(ind_adm)\n",
    "\n",
    "# Displaying the resulting geopandas dataframe `adm_boundaries`.\n",
    "adm_boundaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the indicator using interactive maps\n",
    "# Create a folium map object and set the initial location and zoom level\n",
    "m = folium.Map(location=[adm_boundaries.bounds.iloc[0]['miny'],adm_boundaries.bounds.iloc[0]['minx']], zoom_start=10, tiles=\"CartoDB positron\")\n",
    "\n",
    "# Add a tile layer to the map\n",
    "folium.TileLayer('CartoDB positron',name=\"Light Map\",control=False).add_to(m)\n",
    "\n",
    "# Add a choropleth layer to represent the home location data\n",
    "# folium.Choropleth(\n",
    "#     name=\"home_loc\",\n",
    "#     geo_data=adm_boundaries,\n",
    "#     data=ind_adm,\n",
    "#     columns=[\"name_municipality\",\"total_home_count\"],\n",
    "#     key_on='feature.properties.name_municipality',\n",
    "#     fill_color=\"YlGn\",\n",
    "#     fill_opacity=0.7,\n",
    "#     line_opacity=0.2,\n",
    "#     highlight=True,\n",
    "#     show=False,\n",
    "#     legend_name=\"Population Density\",\n",
    "# ).add_to(m)\n",
    "\n",
    "# Add another choropleth layer to represent the internet usage data\n",
    "folium.Choropleth(\n",
    "    name=\"internet_usage\",\n",
    "    geo_data=adm_boundaries,\n",
    "    data=ind_adm,\n",
    "    columns=[\"municipality\",\"perc_internet\"],\n",
    "    key_on='feature.properties.municipality',\n",
    "    fill_color=\"YlGn\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    highlight=True,\n",
    "    show=True,\n",
    "    legend_name=\"Internet Usage (%)\",\n",
    ").add_to(m)\n",
    "\n",
    "# Define a style function for the GeoJson layer\n",
    "style_function = lambda x: {'fillColor': '#ffffff', \n",
    "                            'color':'#000000', \n",
    "                            'fillOpacity': 0.1, \n",
    "                            'weight': 0.1}\n",
    "\n",
    "# Define a highlight function for the GeoJson layer\n",
    "highlight_function = lambda x: {'fillColor': '#000000', \n",
    "                                'color':'#000000', \n",
    "                                'fillOpacity': 0.50, \n",
    "                                'weight': 0.1}\n",
    "\n",
    "# Create a GeoJson layer with style and highlight functions\n",
    "NIL = folium.features.GeoJson(\n",
    "    adm_boundaries,\n",
    "    style_function=style_function, \n",
    "    control=False,\n",
    "    highlight_function=highlight_function, \n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=['municipality','total_home_count','perc_internet'],\n",
    "        aliases=['Municipality: ','Population Density: ','Internet Usage %: '],\n",
    "        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px; font-weight: bold;\") \n",
    "    )\n",
    ")\n",
    "\n",
    "# Add the GeoJson layer to the map\n",
    "m.add_child(NIL)\n",
    "\n",
    "# Keep the GeoJson layer in front of other layers on the map\n",
    "m.keep_in_front(NIL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a layer control to the map\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "m.save(INDICATOR_PATH+\"ITU_internet_usage.html\")\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if ZONE_FLAG is True\n",
    "if ZONE_FLAG:\n",
    "    # If ZONE_FLAG is True, group the dataframe 'df' by 'zone_classification' and perform aggregations\n",
    "    ind_zone = df.groupBy(['zone_classification']).agg(\n",
    "        count(col('msisdn')).alias('total_home_count'),  # Count the number of 'msisdn' values and alias the column as 'total_home_count'\n",
    "        count(when(col('internet_user')==False, col('msisdn'))).alias('total_no_internet'),  # Count the number of 'msisdn' values where 'internet_user' is False and alias the column as 'total_no_internet'\n",
    "        count(when(col('internet_user')==True, col('msisdn'))).alias('total_internet_ALL'),  # Count the number of 'msisdn' values where 'internet_user' is True, and alias the column as 'total_internet_ALL'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='2G'), col('msisdn'))).alias('total_internet_2G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '2G', and alias the column as 'total_internet_2G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='3G'), col('msisdn'))).alias('total_internet_3G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '3G', and alias the column as 'total_internet_3G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='4G'), col('msisdn'))).alias('total_internet_4G')  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '4G', and alias the column as 'total_internet_4G'\n",
    "    ).orderBy(['zone_classification']).toPandas()\n",
    "    \n",
    "    ind_zone['perc_no_internet'] = (ind_zone['total_no_internet'] / ind_zone['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_zone['perc_internet'] = (ind_zone['total_internet_ALL'] / ind_zone['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_zone['perc_internet_2G'] = (ind_zone['total_internet_2G'] / ind_zone['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_zone['perc_internet_3G'] = (ind_zone['total_internet_3G'] / ind_zone['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_zone['perc_internet_4G'] = (ind_zone['total_internet_4G'] / ind_zone['total_home_count'].replace({0: pd.NA}))\n",
    "    \n",
    "    ind_zone.to_csv(INDICATOR_PATH+\"ind_zone.csv\",sep=\"\\t\",index=False)\n",
    "\n",
    "    # Group the dataframe 'df' by both 'municipality' and 'zone_classification', and perform aggregations\n",
    "    ind_adm_zone = df.groupBy(['municipality','zone_classification']).agg(\n",
    "        count(col('msisdn')).alias('total_home_count'),  # Count the number of 'msisdn' values and alias the column as 'total_home_count'\n",
    "        count(when(col('internet_user')==False, col('msisdn'))).alias('total_no_internet'),  # Count the number of 'msisdn' values where 'internet_user' is False and alias the column as 'total_no_internet'\n",
    "        count(when(col('internet_user')==True, col('msisdn'))).alias('total_internet_ALL'),  # Count the number of 'msisdn' values where 'internet_user' is True, and alias the column as 'total_internet_ALL'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='2G'), col('msisdn'))).alias('total_internet_2G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '2G', and alias the column as 'total_internet_2G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='3G'), col('msisdn'))).alias('total_internet_3G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '3G', and alias the column as 'total_internet_3G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='4G'), col('msisdn'))).alias('total_internet_4G')  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '4G', and alias the column as 'total_internet_4G'\n",
    "    ).orderBy(['municipality','zone_classification']).toPandas()\n",
    "    \n",
    "    ind_adm_zone['perc_no_internet'] = (ind_adm_zone['total_no_internet'] / ind_adm_zone['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_adm_zone['perc_internet'] = (ind_adm_zone['total_internet_ALL'] / ind_adm_zone['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_adm_zone['perc_internet_2G'] = (ind_adm_zone['total_internet_2G'] / ind_adm_zone['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_adm_zone['perc_internet_3G'] = (ind_adm_zone['total_internet_3G'] / ind_adm_zone['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_adm_zone['perc_internet_4G'] = (ind_adm_zone['total_internet_4G'] / ind_adm_zone['total_home_count'].replace({0: pd.NA}))\n",
    "    \n",
    "    ind_adm_zone.to_csv(INDICATOR_PATH+\"ind_adm_zone.csv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 16))  # wider=10, taller=14 (increase this height to make it taller)\n",
    "ax = sns.barplot(\n",
    "    data=ind_adm_zone,\n",
    "    y='municipality',\n",
    "    x='perc_internet',\n",
    "    hue='zone_classification',\n",
    "    orient='h'\n",
    ")\n",
    "\n",
    "# Make axis labels and tick labels smaller\n",
    "ax.set_xlabel('perc_internet', fontsize=10)\n",
    "ax.set_ylabel('municipality', fontsize=10)\n",
    "ax.tick_params(axis='both', labelsize=8)\n",
    "\n",
    "# Optional: shrink legend text too\n",
    "leg = ax.get_legend()\n",
    "if leg is not None:\n",
    "    leg.set_title(None)\n",
    "    for t in leg.texts:\n",
    "        t.set_fontsize(8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CRM_FLAG is True\n",
    "if CRM_FLAG:\n",
    "    # If CRM_FLAG is True, group the dataframe 'df' by 'age_group' and perform aggregations\n",
    "    ind_age = df.groupBy(['age_group']).agg(\n",
    "        count(col('msisdn')).alias('total_home_count'),  # Count the number of 'msisdn' values and alias the column as 'total_home_count'\n",
    "        count(when(col('internet_user')==False, col('msisdn'))).alias('total_no_internet'),  # Count the number of 'msisdn' values where 'internet_user' is False and alias the column as 'total_no_internet'\n",
    "        count(when(col('internet_user')==True, col('msisdn'))).alias('total_internet_ALL'),  # Count the number of 'msisdn' values where 'internet_user' is True, and alias the column as 'total_internet_ALL'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='2G'), col('msisdn'))).alias('total_internet_2G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '2G', and alias the column as 'total_internet_2G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='3G'), col('msisdn'))).alias('total_internet_3G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '3G', and alias the column as 'total_internet_3G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='4G'), col('msisdn'))).alias('total_internet_4G')  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '4G', and alias the column as 'total_internet_4G'\n",
    "    ).orderBy(['age_group']).toPandas()\n",
    "    \n",
    "    ind_age['perc_no_internet'] = (ind_age['total_no_internet'] / ind_age['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_age['perc_internet'] = (ind_age['total_internet_ALL'] / ind_age['total_home_count'].replace({0: pd.NA}))    \n",
    "    ind_age['perc_internet_2G'] = (ind_age['total_internet_2G'] / ind_age['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_age['perc_internet_3G'] = (ind_age['total_internet_3G'] / ind_age['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_age['perc_internet_4G'] = (ind_age['total_internet_4G'] / ind_age['total_home_count'].replace({0: pd.NA}))\n",
    "        \n",
    "    # Convert the resulting dataframe to a Pandas DataFrame\n",
    "    # Save the Pandas DataFrame to a CSV file with the name 'ind_age.csv' at the specified path 'INDICATOR_PATH', using tab as the separator and excluding the index column\n",
    "    ind_age.to_csv(INDICATOR_PATH+\"ind_age.csv\", sep=\"\\t\", index=False)\n",
    "\n",
    "    # Group the dataframe 'df' by 'gender' and perform aggregations\n",
    "    ind_gen = df.groupBy(['gender']).agg(\n",
    "        count(col('msisdn')).alias('total_home_count'),  # Count the number of 'msisdn' values and alias the column as 'total_home_count'\n",
    "        count(when(col('internet_user')==False, col('msisdn'))).alias('total_no_internet'),  # Count the number of 'msisdn' values where 'internet_user' is False and alias the column as 'total_no_internet'\n",
    "        count(when(col('internet_user')==True, col('msisdn'))).alias('total_internet_ALL'),  # Count the number of 'msisdn' values where 'internet_user' is True, and alias the column as 'total_internet_ALL'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='2G'), col('msisdn'))).alias('total_internet_2G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '2G', and alias the column as 'total_internet_2G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='3G'), col('msisdn'))).alias('total_internet_3G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '3G', and alias the column as 'total_internet_3G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='4G'), col('msisdn'))).alias('total_internet_4G')  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '4G', and alias the column as 'total_internet_4G'\n",
    "    ).orderBy(['gender']).toPandas()\n",
    "    \n",
    "    ind_gen['perc_no_internet'] = (ind_gen['total_no_internet'] / ind_gen['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_gen['perc_internet'] = (ind_gen['total_internet_ALL'] / ind_gen['total_home_count'].replace({0: pd.NA}))    \n",
    "    ind_gen['perc_internet_2G'] = (ind_gen['total_internet_2G'] / ind_gen['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_gen['perc_internet_3G'] = (ind_gen['total_internet_3G'] / ind_gen['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_gen['perc_internet_4G'] = (ind_gen['total_internet_4G'] / ind_gen['total_home_count'].replace({0: pd.NA}))\n",
    "       \n",
    "    # Convert the resulting dataframe to a Pandas DataFrame\n",
    "    # Save the Pandas DataFrame to a CSV file with the name 'ind_gen.csv' at the specified path 'INDICATOR_PATH', using tab as the separator and excluding the index column\n",
    "    ind_gen.to_csv(INDICATOR_PATH+\"ind_gen.csv\", sep=\"\\t\", index=False)\n",
    "    \n",
    "    # Group the dataframe 'df' by 'gender' and 'age_group' columns and perform aggregations\n",
    "    ind_gen_age = df.groupBy(['gender', 'age_group']).agg(\n",
    "        count(col('msisdn')).alias('total_home_count'),  # Count the number of 'msisdn' values and alias the column as 'total_home_count'\n",
    "        count(when(col('internet_user')==False, col('msisdn'))).alias('total_no_internet'),  # Count the number of 'msisdn' values where 'internet_user' is False and alias the column as 'total_no_internet'\n",
    "        count(when(col('internet_user')==True, col('msisdn'))).alias('total_internet_ALL'),  # Count the number of 'msisdn' values where 'internet_user' is True, and alias the column as 'total_internet_ALL'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='2G'), col('msisdn'))).alias('total_internet_2G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '2G', and alias the column as 'total_internet_2G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='3G'), col('msisdn'))).alias('total_internet_3G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '3G', and alias the column as 'total_internet_3G'\n",
    "        count(when((col('internet_user')==True) & (col(tech_col)=='4G'), col('msisdn'))).alias('total_internet_4G')  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '4G', and alias the column as 'total_internet_4G'\n",
    "    ).orderBy(['age_group', 'gender']).toPandas()\n",
    "    \n",
    "    ind_gen_age['perc_no_internet'] = (ind_gen_age['total_no_internet'] / ind_gen_age['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_gen_age['perc_internet'] = (ind_gen_age['total_internet_ALL'] / ind_gen_age['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_gen_age['perc_internet_2G'] = (ind_gen_age['total_internet_2G'] / ind_gen_age['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_gen_age['perc_internet_3G'] = (ind_gen_age['total_internet_3G'] / ind_gen_age['total_home_count'].replace({0: pd.NA}))\n",
    "    ind_gen_age['perc_internet_4G'] = (ind_gen_age['total_internet_4G'] / ind_gen_age['total_home_count'].replace({0: pd.NA}))\n",
    "    \n",
    "    # Convert the resulting dataframe to a Pandas DataFrame\n",
    "    # Save the Pandas DataFrame to a CSV file named 'ind_gen_age.csv' at the specified path 'INDICATOR_PATH', using tab as the separator and excluding the index column\n",
    "    ind_gen_age.to_csv(INDICATOR_PATH+\"ind_gen_age.csv\", sep=\"\\t\", index=False)\n",
    " \n",
    "    # Group the dataframe 'df' by 'municipality', 'gender', and 'age_group' columns and perform aggregations\n",
    "    # ind_adm_gen_age = df.groupBy(['municipality', 'gender', 'age_group']).agg(\n",
    "    #     count(col('msisdn')).alias('total_home_count'),  # Count the number of 'msisdn' values and alias the column as 'total_home_count'\n",
    "    #     count(when(col('internet_user')==False, col('msisdn'))).alias('total_no_internet'),  # Count the number of 'msisdn' values where 'internet_user' is False and alias the column as 'total_no_internet'\n",
    "    #     count(when(col('internet_user')==True, col('msisdn'))).alias('total_internet_ALL'),  # Count the number of 'msisdn' values where 'internet_user' is True, and alias the column as 'total_internet_ALL'\n",
    "    #     count(when((col('internet_user')==True) & (col(tech_col)=='2G'), col('msisdn'))).alias('total_internet_2G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '2G', and alias the column as 'total_internet_2G'\n",
    "    #     count(when((col('internet_user')==True) & (col(tech_col)=='3G'), col('msisdn'))).alias('total_internet_3G'),  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '3G', and alias the column as 'total_internet_3G'\n",
    "    #     count(when((col('internet_user')==True) & (col(tech_col)=='4G'), col('msisdn'))).alias('total_internet_4G')  # Count the number of 'msisdn' values where 'internet_user' is True and 'tech_col' is '4G', and alias the column as 'total_internet_4G'\n",
    "    # ).orderBy(['municipality', 'age_group', 'gender']).toPandas()\n",
    "    # # Convert the resulting dataframe to a Pandas DataFrame\n",
    "    # # Save the Pandas DataFrame to a CSV file named 'ind_adm_gen_age.csv' at the specified path 'INDICATOR_PATH', using tab as the separator and excluding the index column\n",
    "    # ind_adm_gen_age.to_csv(INDICATOR_PATH+\"ind_adm_gen_age.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # wider=10, taller=14 (increase this height to make it taller)\n",
    "ax = sns.barplot(\n",
    "    data=ind_gen_age,\n",
    "    y='age_group',\n",
    "    x='perc_internet',\n",
    "    hue='gender',\n",
    "    orient='h'\n",
    ")\n",
    "\n",
    "# Make axis labels and tick labels smaller\n",
    "ax.set_xlabel('perc_internet', fontsize=10)\n",
    "ax.set_ylabel('age_group', fontsize=10)\n",
    "ax.tick_params(axis='both', labelsize=8)\n",
    "\n",
    "# Optional: shrink legend text too\n",
    "leg = ax.get_legend()\n",
    "if leg is not None:\n",
    "    leg.set_title(None)\n",
    "    for t in leg.texts:\n",
    "        t.set_fontsize(8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
